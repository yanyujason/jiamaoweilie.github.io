<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ci | My Octopress Blog]]></title>
  <link href="http://jiamaoweilie.github.io/blog/categories/ci/atom.xml" rel="self"/>
  <link href="http://jiamaoweilie.github.io/"/>
  <updated>2017-03-07T22:34:29+08:00</updated>
  <id>http://jiamaoweilie.github.io/</id>
  <author>
    <name><![CDATA[Your Name]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[持续集成之我见（四）]]></title>
    <link href="http://jiamaoweilie.github.io/blog/2016/10/07/chi-xu-ji-cheng-zhi-wo-jian-si/"/>
    <updated>2016-10-07T21:09:21+08:00</updated>
    <id>http://jiamaoweilie.github.io/blog/2016/10/07/chi-xu-ji-cheng-zhi-wo-jian-si</id>
    <content type="html"><![CDATA[<h2>持续集成成熟度模型</h2>

<p>前面的文章介绍了持续集成的概念、工具等，那么了解这些概念、使用了这些工具就算做到了持续集成吗？答案当然不是这样。我们将在这篇文章中通过持续集成成熟度模型来探讨这个问题。</p>

<p>成熟度模型分为五个级别：</p>

<ul>
<li>入门（Base）：这个级别刚刚跟“模型”沾边，团队不再是所有的流程都要手动去操作。</li>
<li>新手（Beginner）：团队开始认真采用一些持续集成的实践，但是还在刚起步的水平。</li>
<li>中等（Intermediate）：实践已经成熟一些，能够减少错误，提高效率。</li>
<li>优化（Advanced）：团队已经远远超出同行业其他团队，而且效率非常高，能够预防错误的发生。</li>
<li>专家（Expert）：达到这个级别的要求，代价是非常昂贵的，但对某些团队来说，这是目标。</li>
</ul>


<p>其考察维度有四个，分别是构建（Building），部署（Deploying），测试（Testing），和报告（Reporting）。下面我们将从这四个维度分别讨论成熟度模型。</p>

<h3>构建</h3>

<p>以开发人员为中心的持续集成是为了从软件构建中快速得到反馈。但是当项目规模扩大后，构建管理和可控的构建流程就会变得至关重要。可控的构建流程规定了从源码检索到构建、打包、以及存储等的全过程。</p>

<p>在大多数项目的初始阶段，构建工作都是在开发机器上进行，程序员可以根据个人喜好使用IDE或者构建脚本。等项目成熟一些，构建工作就需要考虑测试，甚至发布等问题，这时候我们就开始需要一个成熟可控的构建过程。</p>

<ul>
<li>入门：有明确的构建脚本；有专门的构建机器。（业界水平）</li>
<li>新手：能够自动化构建；至少每天晚上构建一次；能够保存生成的artifacts；</li>
<li>中等：每次提交代码后构建；有依赖管理仓库；</li>
<li>优化：构建过程控制；构建集群；（目标）</li>
<li>专家：虚拟机镜像构建；提交门禁；</li>
</ul>


<p>成熟构建的第一阶段就是标准化构建过程，并且让构建有专门的机器。使用专门的机器构建意味着构建过程不会因为某个开发人员本地环境的变化而影响构建结果。构建不在开发者的机器上进行，意味着代码是从一个代码控制平台获得，并遵循一定的规则：比如每次获取每个分支的最新代码，或者打某种标签的代码。做到了这些，团队就达到了入门级。</p>

<p>新手级别是团队采取一定行动使得构建执行自动化，并且能够每天至少执行一次。构建服务器可以指挥机器按照规则pull源代码，并且执行构建脚本。</p>

<p>中等级别的团队的显著特征是开始进行依赖管理，包括对子项目的依赖和第三方库文件的依赖。团队使用依赖管理工具来追踪库文件，并且在构建时提供这些库文件，而不是将依赖放在代码库中。类似的，所依赖的子项目也是通过依赖管理工具管理和使用。构建过程会被保存（可能放在某网络服务器上，或是直接放在CI服务器上），打标签以便识别，并且定期做清理。到达这个级别，团队已经采取了持续构建，能在程序员提交代码后或者依赖变更后自己构建，并且提供有意义的反馈。一些大规模团队将使用分布式构建设备来并行处理数量众多的构建。</p>

<p>优化级别的团队将会关注对构建过程的控制，这种团队不光追踪代码和依赖的变化，也追踪构建过程的变化。对于构建过程的修改需要经过批准，因此登录到构建机器，修改构建服务器配置等操作都是被严格限制的。大规模的组织或者追求快速集成测试的组织往往需要优化级别的构建过程。随着每天构建次数的增加，或者构建环境的多样化（比如同时需要Windows设备和Linux设备），单独的构建设备就显得力不从心，我们就需要一个集群来自动选择构建集群并进行负载均衡。</p>

<p>专家级别要求团队必须能够完美地重新构建以前的发布版本。团队将使用各种各样的技术来确保每个环境的可重复性。为了运行构建过程，我们使用一些缜密的脚本，从安装操作系统开始准备构建机器，或者使用虚拟机镜像来运行版本化的构建过程。还有一些团队使用提交门禁制度使得build常绿，一旦某次提交使得构建失败，那么这次提交就会被reject掉。</p>

<h3>部署</h3>

<p>部署是将软件发布给用户，或者其他消费者。对于web应用来说，部署意味着将应用安装到一系列的web服务器上，并且更新数据库或者其他静态服务器。</p>

<p>部署的最开始一般都是手工进行，像我的上个项目，程序员将本地的部署文件拷贝到目标机器上，然后手动进行替换和安装。手工过程往往非常慢，而且特别容易出错，为了发布新的软件，开发人员和测试人员往往需要整晚加班。很多软件都需要多环节部署，而且不同环境的部署方法和步骤往往不一样，更加增大了手工部署的难度，这时候，我们就要寻找更加快捷高效的方法。</p>

<ul>
<li>入门：有少量部署脚本；（业界水平）</li>
<li>新手：自动部署到测试环境；有比较规范的部署；</li>
<li>中等：自动部署到测试和产品环境；在所有环境都有标准的流程；（目标）</li>
<li>优化：测试门禁部署；数据库的自动化部署；协调部署；</li>
<li>专家：持续部署到产品环境；</li>
</ul>


<p>入门级别的团队能在部署时使用一些的辅助性脚本，相对于纯手工部署来说，这已经是很大的进步。目前来讲，大部分团队都会使用一些辅助部署脚本，达到入门级的水平。</p>

<p>新手级别的团队能够才测试环境实现的自动部署。通过一系列脚本的帮助，系统可以一键部署到一个或者所有测试环境。这将大大减少负责部署人员的工作量，也可以减少测试团队等待部署的时间。自动部署到第一个测试环境，是持续集成的部署维度达到新手水平的标志。根据团队情况，在不影响部署的情况下，部署工作应该发生在每一次成功构建之后，或者是以固定的间隔时间进行。新手级别的另一个标志是：在各个环境上建立标准化的部署流程。虽然部署中间还充满各种变数，但是在软件开发生命周期中，尽早的部署成功不但能增加团队信心，更能及早的发现问题，增加最终部署成功的几率。</p>

<p>中等级别的团队已经能够将关注点放在产品环境的部署。产品可以一键触发部署流程，然后自动部署到产品环境，并且相应的发布版本可以做到灾难恢复。那些已经将产品自动部署的测试环境的团队，应该把中等级别作为目标，如果在所有环境中进行完全一致的部署过程，那么在生产环境部署时，会极大地减少最后一刻失败的可能性。</p>

<p>优化级别的团队的特征是：将通过质量测试检验的版本全部自动地部署到部分或全部测试环境中。例如，得到测试经理的批准后，让某个构建版本自动地安装到压力测试环境中。另外，他们还攻克了一些部署过程的难题，比如数据库部署，向内容管理系统跟新信息，提升业务敏捷工具的报告。进阶团队的另一个典型特征是，协调部署。他们不是简单的部署一次构建的结果，而是部署一系列的有内在联系的一组构建，肯能是一个应用，或者一系列Web服务。这样有助于确保系统中的所有已经被测试的组件部署到同一组生产环境。将系统部署细化成一系列的组件部署。</p>

<p>专家级别的团队追求从完全没有任何人工干预的持续部署。也就是说，在构建完成得到一个新的版本后，依次自动部署到所有一系列的测试环境，然后经过所有的自动化测试后立即自动部署该版本到生产环境，而且整个系统必须具有自动回滚和严格的监控手段，对自动化测试的要求特别高。有些Web应用甚至可以做到一个小时内完成从源代码控制到发布的全过程。在竞争激烈的当今社会，快速的发布新功能，也可以增加企业的竞争力，减轻大规模发布的风险。</p>

<h3>测试</h3>

<p>持续集成与自动化测试的层次息息相关。在很多企业中，自动化测试的重视程度很低，能力很弱，一个团队开发完一个产品，然后部署到测试环境，让测试人员进行手工测试，然后进行发布。测试人员几乎到淹没在无穷无尽的重复劳动中，特别疲惫，容易出错，而且只有发现问题的流程很长。如果团队在更加关注自动化测试，增加自动化测试脚本，他们就能很快发现问题或缺陷，从而在生产率和信心方面都会有所增加。</p>

<ul>
<li>入门：有少量自动化测试；（业界水平）</li>
<li>新手：每次构建都进行快速测试；测试失败及时通知；</li>
<li>中等：静态代码分析；具有每天至少执行一次得自动化功能测试；（目标）</li>
<li>优化：高测试覆盖率；安全扫描；基于风险的手工测试；</li>
<li>专家：100%测试覆盖率；</li>
</ul>


<p>大多数团队或多或少都有一些自动化测试，也行是少量的单元测试，或者是一些保证基本功能的测试脚本。这些测试可以帮助我们及时，快速的发现产品的基本功能性问题。入门级别的团队基本处于这个水平，刚刚开始适应自动化测试。</p>

<p>新手级别的团队应该有一套在本次构建时都会自动运行的测试。这些测试保证了软件在任何时间都是可以工作的，能够极大的增加团队信心。任何一次测试失败，系统都应该及时通知开发团队，使得问题能够及时得到修复。测试失败及时通知开发团队，也是达到新手级别的一个标志。</p>

<p>中等级别的团队具备构建时快速测试的特征外，还是得自动化测试更加多样化。一个中级级别的团队不光需要具有快速的单元测试和手工测试，还需具有自动化的功能测试，而且使用一些持续集成工具进行静态代码扫描。静态代码扫描可能不是每天进行，但是必须周期性的进行，一旦代码扫描出现一些严重的代码质量问题，就必须要阻断构建过程，待修复后才能发布产品。</p>

<p>优化级别的团队以“完整测试”为标志，每种类型的测试都要尽其所能的提供最大的作用。单元测试能够覆盖系统中的所有复杂代码和逻辑部分，功能测试能够覆盖系统中所有的重要功能，当然边界测试和随机测试也是必不可少的。同时，还需要频繁的运行静态代码扫描，并补充那些以工具执行的运行时分析和安全分析来分析那些因测试不足或无法测试而遗漏的问题。为了产品的多环境运行，测试会被分配在多种系统下运行，以提供快速的反馈。达到优化级别需要团队付出相当大的投入，但是这些投入对团队来说特别有意义，尤其对那些缺陷的成本很高且需要保持高速前进的团队来说。假如没有这些需求，一般达到中等级别已经能够满足要求。</p>

<p>专家级别团队的典型特征是追求100%的测试覆盖率。尽管100%测试覆盖率的定义在不断变化，但是它反映出至少产品的每行代码都被测试覆盖到。但是，在实际工作中，往往存在一个收益减少点，一味的追求100%覆盖往往意味着浪费。对于这些团队来说，满足并保持100%的测试覆盖率可能也是一个自豪感与动力的源泉。对于进阶级团队来说，如果曾经发现的确错过了一些非常重要的测试的话，要求100%的测试覆盖也未尚不可。但对于大多数团队来说，完全不需要刻意达到这个要求。</p>

<h3>报告</h3>

<p>报告对持续集成至关重要，它应该包括软件质量、软件内容、以及持续集成过程的相关信息。如果产生的信息无序且繁杂，我们就无法提取有用信息，那么对于软件质量的提高也没有什么作用。所以越成熟的团队，信息的可视化程度就越高，用户越容易从中得到有用信息。</p>

<ul>
<li>入门：工具生成报告；生成报告者可见；</li>
<li>新手：及时发布最近一次构建报告；团队可见；</li>
<li>中等：报告历史易追踪；报告互通性</li>
<li>优化：趋势分析报告；</li>
<li>专家：交叉分析</li>
</ul>


<p>持续集成成熟度模型的四个方面大概就是这个样子，我们在实际使用时应该根据项目自身情况，选择适合自身项目的各个维度。<del>真的实在编不下去了，等我看看书再继续充实吧</del></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[持续集成之我见（三）]]></title>
    <link href="http://jiamaoweilie.github.io/blog/2016/09/29/chi-xu-ji-cheng-san/"/>
    <updated>2016-09-29T20:16:22+08:00</updated>
    <id>http://jiamaoweilie.github.io/blog/2016/09/29/chi-xu-ji-cheng-san</id>
    <content type="html"><![CDATA[<h2>使用Jenkins搭建持续集成环境</h2>

<p>下面我们以Jenkins为例，介绍一些如何快速搭建一个持续集成环境。</p>

<h3>安装Jenkins</h3>

<p>Jenkins可以运行在多种操作系统上，这里主要介绍如何使用docker安装。首先，你需要在本机上安装<a href="http://docker.io/">docker</a>,然后执行一下命令来pull Jenkins的官方镜像：</p>

<pre><code>docker pull jenkins
</code></pre>

<p>然后运行如下命令来run该镜像：</p>

<pre><code>docker run -d -p 49001:8080 -v $PWD/jenkins:/var/jenkins_home -t jenkins
</code></pre>

<p>在上述命令中，container中的 <code>/var/jenkins_home</code> 文件夹被映射到当前路径的 <code>jenkins/</code>路径下，container中的8080端口被映射到本地的49001端口。</p>

<p>至此，我们已经可以 <a href="http://localhost:49001">http://localhost:49001</a> 访问Jenkins, 并看到如下 页面。</p>

<p><img src="/images/img_for_ci/jenkins_start.jpg" alt="输入初始密码解锁Jenkins" /></p>

<p>系统要求你输入Administrator的初始密码来解锁系统，并提示了该密码的所在位置。对于docker来说，你可以输入如下操作查看该container的log，找到密码。</p>

<pre><code>docker ps -a // 查看当前运行container
</code></pre>

<p><img src="/images/img_for_ci/image.jpg" alt="container的运行状态" /></p>

<pre><code>docker logs 136d491d56d8 //数字表示Jenkins的container id
</code></pre>

<p>然后就可以在log中找到如下的初始密码：</p>

<p><img src="/images/img_for_ci/password.jpg" alt="初始密码" /></p>

<p>然后我们可以根据页面提示，安装推荐的plugin，完成注册等初始化操作，就可以看着Jenkins的工作页面。</p>

<p><img src="/images/img_for_ci/jenkins.jpg" alt="Jenkins 首页" /></p>

<p>至此，我们就完成了所有的安装和初始化的工作。</p>

<h3>使用Jenkins</h3>

<p>对于Jenkins 2.x版本，你可以使用以前的方式创建pipeline，当然比较方便的是Pipeline as code。下面我用一个简单的例子，说明如何使用脚本创建pipeline。</p>

<h4>准备工作</h4>

<p>本文中的例子是一个简单的maven构建的java项目，所以准备工作为jenkins安装好java和maven。在Jenkins的首页点击Manage Jenkins -> Global Tool Configuration，然后如下图所示配置：</p>

<p><img src="/images/img_for_ci/jdk.jpg" alt="jdk" /></p>

<p><img src="/images/img_for_ci/maven.jpg" alt="maven" /></p>

<h4>Pipeline创建</h4>

<p>完成环境准备工作，我们就可以开始创建Pipeline。在首页点击New Item，然后输入一个item name，选择Pipeline，最后点击OK。</p>

<p><img src="/images/img_for_ci/new.jpg" alt="创建item" /></p>

<p>创建完item之后，就会进入配置页面，我们在这里需要配置trigger方式，以及Pipeline脚本等。配置pipeline脚本有两种方式，一种是写在页面上，一种是写在源代码中。</p>

<p><img src="/images/img_for_ci/script.jpg" alt="配置item" /></p>

<p>配置完成后，点击Build Now，就可以开始build我们的项目了。</p>

<p><img src="/images/img_for_ci/build.jpg" alt="构建状态" /></p>

<p>如图是我们的构建结果，一列是一个stage，每个stage执行脚本中定义的操作。</p>

<h4>Pipeline说明</h4>

<p>上述Pipeline有如下的基本概念：</p>

<ul>
<li>Stage: 一个Pipeline可以划分为若干个Stage，每个Stage代表一组操作。注意，Stage是一个逻辑分组的概念，可以跨多个Node。</li>
<li>Node: 一个Node就是一个Jenkins节点，或者是Master，或者是Agent，是执行Step的具体运行期环境。</li>
<li>Step: Step是最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类Jenkins Plugin提供。</li>
</ul>


<p>具体构成如下：</p>

<ul>
<li>Stage View: Pipeline的视觉展现，类似于上图。</li>
<li>Jenkinsfile: Pipeline的定义文件，由Stage，Node，Step组成，一般存放于代码库根目录下，如下所示。</li>
</ul>


<pre><code class="js">node {
   def mvnHome
   stage('Preparation') { // for display purposes
      // Get some code from a GitHub repository
      git 'https://github.com/jglick/simple-maven-project-with-tests.git'
      // Get the Maven tool.
      // ** NOTE: This 'M3' Maven tool must be configured
      // **       in the global configuration.           
      mvnHome = tool 'M3'
   }
   stage('Build') {
      // Run the maven build
      if (isUnix()) {
         sh "'${mvnHome}/bin/mvn' -Dmaven.test.failure.ignore clean package"
      } else {
         bat(/"${mvnHome}\bin\mvn" -Dmaven.test.failure.ignore clean package/)
      }
   }
   stage('Results') {
      junit '**/target/surefire-reports/TEST-*.xml'
      archive 'target/*.jar'
   }
}
</code></pre>

<p>Jenkins 2.x 默认支持三种类型的Pipeline有三种，普通Pipeline，Multibranch Pipeline和Organization Folders，后两种其实是批量创建一组普通Pipeline的快捷方式，分别对应于多分支的应用和多应用的大型组织。注意，要获取Organization Folders的支持需要额外安装Plugin。</p>

<p>至此我们已经介绍了Jenkins的安装以及Pipeline as Code的基本用法，更多关于Jenkins的操作请参见<a href="https://jenkins.io/doc/">官方文档</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[持续集成之我见（二）]]></title>
    <link href="http://jiamaoweilie.github.io/blog/2016/09/28/chi-xu-ji-cheng-er/"/>
    <updated>2016-09-28T10:41:35+08:00</updated>
    <id>http://jiamaoweilie.github.io/blog/2016/09/28/chi-xu-ji-cheng-er</id>
    <content type="html"><![CDATA[<h2>持续集成工具推荐</h2>

<p>前面的文章提到了一些关于持续集成的概念，以及持续集成工具应该具有的功能，和团队成员应该遵守的ci纪律，下面我讲介绍几种常用的持续集成的工具。</p>

<h3>Jenkins</h3>

<p><a href="https://jenkins.io/">Jenkins</a>是一个应用广泛的开源持续集成工具，它提供了数百个插件来支持项目的自动化编译、测试、部署等，使得开发人员可以从繁杂的集成中解脱出来，专注在更加重要的业务逻辑实现上。同时 Jenkins 能实时监控集成中存在的错误，提供详细的日志文件和提醒功能，还能用图表的形式形象地展示项目构建的趋势和稳定性。Jenkins可以很好的支持各种语言（比如：java, c#, php等）的项目构建，也完全兼容ant、maven、gradle等多种第三方构建工具，同时跟svn、git能无缝集成，也支持直接与知名源代码托管网站，比如github、bitbucket直接集成。关于如何使用Jenkins，后续文章会做详细的介绍。</p>

<h3>Travis CI</h3>

<p><a href="https://travis-ci.org/">Travis CI</a>是一个可以与Github完美集成的开源持续集成工具，当用户登录到Travis CI之后，可以同步的从界面中看到该用户Github账号中的repo，用户可以方便的为这些repo中的代码创建ci。它不需要复杂的界面，允许你通过在源码里面增加一个名为<code>.travis.yml</code>的文件来对构建进行配置。</p>

<pre><code class="yml">language: ruby
rvm:
 - 2.2
 - jruby
 - rbx-2
</code></pre>

<p>上文中的配置文件告诉Travis CI这是一个Ruby项目，将会使用rake构建。接下来的rvm告诉Travis CI，这个项目的测试环境是Ruby 2.2，最新版本的JRuby和Rubinius。用户只需将这个配置文件提交到代码库中就可以触发Travis CI构建项目，并在构建页面来查看项目构建状态。</p>

<h3>Concourse</h3>

<p><a href="http://concourse.ci/">Concourse</a>是一个开源的持续集成工具，它使用yaml文件来配置pipeline，以及设置其他无需配置的安装。根据其开发团队的说法，它的主要优点是：</p>

<ul>
<li>为pipeline提供明确的、第一级的支持；</li>
<li>在容器中运行相互隔离的构建工作；</li>
<li>可避免使用雪花型构建服务器；</li>
<li>能够方便地访问日志；</li>
<li>概念简单。</li>
</ul>


<p>Concourse的最终目标是以尽可能少的变化部分提供一种具有表达性的系统。它设立了三种核心概念：任务、资源、作业。</p>

<ul>
<li>任务（Task）是执行的基本单元，表现为在一个全新启动的容器中所运行的脚本。容器已经经过了预处理，因此其中包含了一个输入与输出目录，任务脚本可在这些目录中运行。</li>
<li>资源（Resource）则表现为版本化资源的抽象位置，例如某个repo。资源也可用于对进入或退出某个管道的外部依赖进行建模，或是表示更抽象的概念，例如时间触发器。资源的变更可被检测、获取、以及发布。不同的资源类型（例如Git、AWS S3或触发器）可用于封装用于管道的各种样板代码，为Concourse的扩展提供了一个可适配的接口。</li>
<li>作业（Job）是由资源与任务构成的，通过构建计划实现。作业可由资源的变更所触发，也可以选择手动触发，以实现人工批准流程。</li>
</ul>


<p>一个作业计划的执行实例被称为一次构建（Build），Concourse中的构建是可重复使用的，因为其中的任务在新的容器中也将重新运行。因此，构建的工作线程不会受到之前运行结果的变更所影响。此外，如果某次构建失败了，也可以通过一个名为Fly的Concourse命令行工具在某个容器中再一次在本地运行，通过这种方式实现更快的开发周期。</p>

<h3>Go</h3>

<p><a href="https://www.go.cd/">Go</a>是ThoughtWorks开发的一款开源持续集成工具。它采用了Server-Agent模式，Server用来展示和配置pipeline的界面，并存放构建出来的Artifacts；Agent用来执行构建操作，一个Server可以和多个Agent建立连接，Agent支持多个主流的操作系统。</p>

<p><img src="/images/img_for_ci/go_cd.jpg" alt="Server Agent模式" /></p>

<p>每种工具的具体使用方法，请详见各自的文档。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[持续集成之我见（一）]]></title>
    <link href="http://jiamaoweilie.github.io/blog/2016/09/27/chi-xu-ji-cheng/"/>
    <updated>2016-09-27T22:12:38+08:00</updated>
    <id>http://jiamaoweilie.github.io/blog/2016/09/27/chi-xu-ji-cheng</id>
    <content type="html"><![CDATA[<h2>什么是持续集成</h2>

<p><a href="http://baike.baidu.com/view/5253255.html">持续集成（Continuous integration）</a>是一种软件开发实践，即团队开发成员经常集成它们的工作，通过每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。</p>

<h2>为什么要持续集成</h2>

<p>在我刚到上一个项目时，团队成员工作在下面一种工作模式中。项目代码在开发人员的本地，一个人负责一个或多个小项目。需求分析人员写好需求文档，然后和开发人员、测试人员一起开一个需求评审会，然后开发人员开始写代码，测试人员开始写测试文档。当开发完成需求后，手动的完成代码打包，然后手动部署到SIT环境供测试人员进行测试。部署完成后，测试人员就开始了疯狂的寻找bug之旅，将bug录入系统并交给开发去改，周而复始，完成上面的往复。直至此环境的测试工作完成，然后开发人员又去手动部署到UAT环境，依旧完成上次的循环，直至项目发布。在项目发布之前还会将代码拷贝给其他部门进行代码规范、安全等审查，在针对审查出来的问题进行改正，往往这个改动又会引入其他问题。</p>

<p>这种系统，采用传统的模式开发，在代码开发完成后才集成起来进行测试，很多在项目早期就存在的bug都是在完成开发工作之后才被发现，不利于定位问题，增加工作难度，而且每次部署都是手动的，有的环境甚至有几十台机器需要部署，单单打包部署这种重复劳动就使开发人员的工作苦不堪言。开发从来不写单元测试，甚至也不怎么认真进行自测，完成代码就交给测试去测，甚至还会发现将输入页面的用户名和密码的输入框写反了这种低级错误，而且项目一旦出现问题就是为什么测试人员没有测出来这个bug，我甚至遇到过因为项目出了线上bug而将测试人员开除的情况，这使得测试人员的工作也是压力山大。</p>

<p>在这种困境之下徘徊很久，项目组引入持续集成的概念，使用git作为版本控制工具，使用gradle作为构建工具，使用Jenkins搭建ci，增加自动化的代码编译、审查、单元测试、集成测试，以及自动化部署等。从艰难推行，到客服困难运行了一段时间之后，发现持续集成给项目带来了很多好处。</p>

<h3>减少重复过程</h3>

<p>在以前的工作模式中，代码的编译、审查、测试、打包、部署、反馈等工作，都是手动进行，费时费力，而且容易出错。通过自动化的持续集成可以将这些重复的动作都变成自动化的，无需太多人工干预，减少重复的过程，可以节省时间、费用和工作量，让人们的时间更多的投入到动脑筋的、更高价值的事情上。</p>

<h3>减少风险</h3>

<p>在一个项目中，最不可靠最容易出错的因素就是人，减少大量重复的人力工作就大大的降低了项目的风险。另外，一天中进行多次的集成，并做了相应的自动化测试，这样有利于检查缺陷，了解软件的健康状况，减少假定。利用持续集成，开发人员对源代码进行的小改动，会及时和其他的代码进行集成，一旦出现问题，项目成员马上就会被通知到，问题也会在第一时间被修复。</p>

<h3>任何时间、任何地点生成可部署的软件</h3>

<p>开发提交代码之后，只有构建成功，就会生成一个在任何时间可部署的软件产品，可恐怕是对用户来说最显而易见的好处。不采用持续集成的情况下，项目中的问题有可能到交付前的集成测试的时候才发现，有可能会导致延迟发布产品，而在急于修复这些缺陷的时候又有可能引入新的缺陷，最终可能导致项目失败。</p>

<h3>增强项目的可见性</h3>

<p>持续集成可以带来两点积极效果：</p>

<ul>
<li>有效决策：持续集成系统为项目构建状态和品质指标提供了及时的信息，有些持续集成系统可以报告功能完成度和缺陷率。</li>
<li>注意到趋势：由于经常集成，我们可以看到一些趋势，如构建成功或失败、总体品质以及其它的项目信息。</li>
</ul>


<p>如果没有真实或最新的数据提供支持，项目就会遇到麻烦，每个人都会提出他最好的猜测。通常，项目成员通过手工收集这些信息，增加了负担，也很耗时。</p>

<h3>建立团队对开发产品的信心</h3>

<p>采用持续集成，团队成员可以清楚的知道每一次构建的结果，看到自己对软件的改动造成了哪些影响，结果怎么样，这种即时、可视化的信息可以增加了团队的信心。</p>

<h2>如何做到持续集成</h2>

<p>根据上文的描述，我们使用的持续集成工具需要做到下面几个功能：</p>

<ul>
<li>自动构建：构建工作需要在提交代码之后自动执行，要求无人值守，如果人工来操作，那么持续集成就毫无魅力。</li>
<li>发现版本库的变更：通过轮询或者定时，触发持续集成工具发现版本库的变更。</li>
<li>反馈机制：在出现问题时，能及时的把问题反馈给正确的人（提交者、测试者、管理者）</li>
<li>回滚：在出现问题后，拥有回滚到可交付的能力。</li>
<li>纯净的构建环境：每一次都应该把之前的环境删除干净，让每一次构建都是一个新的构建。</li>
<li>完善的集成功能：代码的测试，审查，部署都应该做到完善。如果单纯的利用它做持续的编译，那就是大材小用了。</li>
</ul>


<p>使用持续集成工具搭建构建流水线仅仅是第一步，全组成员依照默认的纪律使用ci才能使其最大化发生作用。一个开始准备要提交新修改的代码时，应该遵循如下步骤：</p>

<ol>
<li>查看ci是否正在构建。如果有的话，你要等它运行完。如果构建失败了，你要与团队成员一起将其修复。</li>
<li>一旦构建完成且测试全部通过，就从版本控制库中更新最新的代码到本地。</li>
<li>在本地执行构建脚本，运行测试，以确保代码在本地可以正常工作。</li>
<li>如果本地构建成功，就将代码提交到远端代码库。</li>
<li>等待这次提交的构建结果。</li>
<li>如果构建失败，就应该停下来手头的工作，修复构建问题，然后转到步骤3。</li>
<li>如果构建成功，你就可以happy的进行接下来的工作了。</li>
</ol>


<p>至此，我们对持续集成已经有了一个简单的认识，在接下来的文章中，我将会介绍一些持续集成工具，以及如何使用这些工具。</p>
]]></content>
  </entry>
  
</feed>
